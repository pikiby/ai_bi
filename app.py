# app.py
# –ë–õ–û–ö: –∏–º–ø–æ—Ä—Ç–æ–≤ –∏ –±–∞–∑–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞
import os
import sys
import re
import subprocess
import streamlit as st
from openai import OpenAI
from retriever import retrieve
from sql_assistant import run_sql_assistant  # <‚Äî –¥–æ–±–∞–≤–∏–ª–∏

st.set_page_config(page_title="Streamline Chat + RAG", page_icon="üí¨", layout="centered")

# ----- –ï–î–ò–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Chroma -----
CHROMA_PATH = os.getenv("KB_CHROMA_PATH", "data/chroma")
COLLECTION_NAME = os.getenv("KB_COLLECTION_NAME", "kb_docs")

def _validate_collection_name(name: str) -> str:
    n = (name or "").strip().lower()
    if not re.fullmatch(r"[a-z0-9_]{3,63}", n):
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {name!r}. –†–∞–∑—Ä–µ—à–µ–Ω—ã 3‚Äì63 —Å–∏–º–≤–æ–ª–∞: [a-z0-9_].")
    return n

COLLECTION_NAME = _validate_collection_name(COLLECTION_NAME)
os.makedirs(CHROMA_PATH, exist_ok=True)
os.makedirs("docs", exist_ok=True)

# ----- OpenAI –∫–ª—é—á -----
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞.")
    st.stop()
client = OpenAI(api_key=api_key)

# –ë–õ–û–ö: —Å–∞–π–¥–±–∞—Ä ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ + –∫–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ + –ü–ï–†–ï–ö–õ–Æ–ß–ê–¢–ï–õ–¨ –†–ï–ñ–ò–ú–ê
with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    model = st.selectbox(
        "–ú–æ–¥–µ–ª—å",
        options=[
            "gpt-4o-mini",
            "gpt-4o",
            "gpt-4.1-mini",
        ],
        index=0,
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05)
    system_prompt = st.text_area(
        "System prompt",
        value="–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        height=120,
    )

    # ‚Üê –≤–æ—Ç –æ–Ω, –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å
    mode = st.radio("–†–µ–∂–∏–º", ["–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (RAG)", "–î–∞–Ω–Ω—ã–µ (SQL)"], index=0)

    st.caption("–ò—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –º–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –∫–Ω–æ–ø–∫–æ–π –Ω–∏–∂–µ.")
    if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", key="clear_history"):
        st.session_state["messages"] = []
        st.rerun()

    st.divider()
    st.subheader("–ò–Ω–≥–µ—Å—Ç –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    st.caption(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è: {COLLECTION_NAME!r} ¬∑ –ü—É—Ç—å –∫ –∏–Ω–¥–µ–∫—Å—É: {CHROMA_PATH!r}")
    if st.button("–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å docs/"):
        with st.status("–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã‚Ä¶", expanded=True) as status:
            env = os.environ.copy()
            env["KB_COLLECTION_NAME"] = COLLECTION_NAME
            env["KB_CHROMA_PATH"] = CHROMA_PATH
            proc = subprocess.run(
                [sys.executable, "ingest.py"],
                capture_output=True,
                text=True,
                env=env,
            )
            st.code(proc.stdout or "(–Ω–µ—Ç stdout)")
            if proc.returncode == 0:
                status.update(label="–ì–æ—Ç–æ–≤–æ", state="complete")
            else:
                st.error(proc.stderr)

# –ë–õ–û–ö: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
st.session_state.setdefault("messages", [])

# –ë–õ–û–ö: –∑–∞–≥–æ–ª–æ–≤–∫–∏
st.title("Chat ‚Üí ChatGPT —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π (RAG) –∏ –¥–∞–Ω–Ω—ã–º–∏ (SQL)")
st.caption("–°–ª–µ–≤–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º. –ï—Å—Ç—å –∫–Ω–æ–ø–∫–∞ –¥–ª—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ docs/.")

# –ë–õ–û–ö: —Ä–µ–Ω–¥–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# –ë–õ–û–ö: –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_input = st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶")
if user_input:
    # 1) —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    if mode == "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (RAG)":
        # 2) –¥–æ—Å—Ç–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ Chroma
        try:
            ctx_docs = retrieve(
                user_input,
                k=5,
                chroma_path=CHROMA_PATH,
                collection_name=COLLECTION_NAME
            )
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Ä–µ—Ç—Ä–∏–≤–∞: {e}")
            # –ù–ò–ß–ï–ì–û –Ω–µ —á–∏—Å—Ç–∏–º, –Ω–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ—Å—å —Ä–µ–Ω–¥–µ—Ä
            # –ú–æ–∂–Ω–æ –¥–æ–ø–∏—Å–∞—Ç—å ¬´—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π¬ª –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞:
            st.session_state.messages.append({"role": "assistant", "content": f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç: {e}"})
            ctx_docs = []

        context = "\n\n".join([f"[{i+1}] {d['text']}" for i, d in enumerate(ctx_docs)]) or "‚Äî"
        
        # 3) —Å–æ–±—Ä–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ (–Ω–µ –ø—É—Ç–∞–π —Å –∏—Å—Ç–æ—Ä–∏–µ–π UI)
        llm_messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user",
            "content": (
                f"QUESTION:\n{user_input}\n\n"
                f"CONTEXT:\n{context}\n\n"
                f"–ü—Ä–∞–≤–∏–ª–∞: –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–æ CONTEXT. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏."
            )}
        ]

        # 4) –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        with st.chat_message("assistant"):
            placeholder = st.empty()
            stream_text = ""
            stream = client.chat.completions.create(
                model=model,
                messages=llm_messages,
                temperature=temperature,
                stream=True,
            )
            for chunk in stream:
                delta = chunk.choices[0].delta.content or ""
                stream_text += delta
                placeholder.markdown(stream_text)

        # 5) —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç
        st.session_state.messages.append({"role": "assistant", "content": stream_text})

        # 6) –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        if ctx_docs:
            with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                for i, d in enumerate(ctx_docs, 1):
                    st.write(f"[{i}] {d['source']} ‚Äî {d['path']}  (score={d['score']:.4f})")

    else:
        # --- –†–ï–ñ–ò–ú SQL ---
        try:
            database = "db1"
            allowed_tables = ["total_active_users", "total_active_users_rep_mobile_total"]  # –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

            sql, df = run_sql_assistant(
                question=user_input,
                database=database,
                allowed_tables=allowed_tables,
                model=model,
            )

            with st.chat_message("assistant"):
                st.markdown("**–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL:**")
                st.code(sql, language="sql")
                st.markdown("**–†–µ–∑—É–ª—å—Ç–∞—Ç:**")
                st.dataframe(df.to_pandas(), use_container_width=True)

            st.session_state.messages.append({
                "role": "assistant",
                "content": f"SQL –≤—ã–ø–æ–ª–Ω–µ–Ω. –°—Ç—Ä–æ–∫: {df.height}, —Å—Ç–æ–ª–±—Ü–æ–≤: {df.width}."
            })

        except Exception as e:
            with st.chat_message("assistant"):
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏/–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ SQL: {e}")
            st.session_state.messages.append({"role": "assistant", "content": f"–û—à–∏–±–∫–∞: {e}"})
