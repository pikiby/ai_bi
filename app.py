# app.py
# –ë–õ–û–ö: –∏–º–ø–æ—Ä—Ç–æ–≤ –∏ –±–∞–∑–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞
import os
import sys
import subprocess
import streamlit as st
from openai import OpenAI
from retriever import retrieve

st.set_page_config(page_title="Streamline Chat + RAG", page_icon="üí¨", layout="centered")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞.")
    st.stop()
client = OpenAI(api_key=api_key)

# –ë–õ–û–ö: —Å–∞–π–¥–±–∞—Ä ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ + –∫–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    model = st.selectbox(
        "–ú–æ–¥–µ–ª—å",
        options=[
            "gpt-4o-mini",   # –±—ã—Å—Ç—Ä—ã–π/–¥–µ—à—ë–≤—ã–π
            "gpt-4o",        # –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ
            "gpt-4.1-mini",
        ],
        index=0,
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05)
    system_prompt = st.text_area(
        "System prompt",
        value="–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        height=120,
    )
    st.caption("–ò—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –º–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –∫–Ω–æ–ø–∫–æ–π –Ω–∏–∂–µ.")
    if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
        st.session_state.messages = []

    st.divider()
    st.subheader("–ò–Ω–≥–µ—Å—Ç –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    st.caption("–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ docs/ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å Chroma.")
    if st.button("–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å docs/"):
        with st.status("–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã‚Ä¶", expanded=True) as status:
            # –í–´–ó–û–í ingest.py –ö–ê–ö –û–¢–î–ï–õ–¨–ù–û–ì–û –ü–†–û–¶–ï–°–°–ê
            proc = subprocess.run(
                [sys.executable, "ingest.py"],
                capture_output=True,
                text=True
            )
            st.code(proc.stdout or "(–Ω–µ—Ç stdout)")
            if proc.returncode == 0:
                status.update(label="–ì–æ—Ç–æ–≤–æ", state="complete")
            else:
                st.error(proc.stderr)

# –ë–õ–û–ö: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
if "messages" not in st.session_state:
    st.session_state.messages = []

# –ë–õ–û–ö: –∑–∞–≥–æ–ª–æ–≤–∫–∏
st.title("Chat ‚Üí ChatGPT —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π (RAG)")
st.caption("–°–ª–µ–≤–∞ –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é. –í–æ–ø—Ä–æ—Å—ã –≤–Ω–∏–∑—É ‚Äî –æ—Ç–≤–µ—Ç—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ docs/.")

# –ë–õ–û–ö: —Ä–µ–Ω–¥–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# –ë–õ–û–ö: –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_input = st.chat_input("–í–æ–ø—Ä–æ—Å –ø–æ –≤–∞—à–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π‚Ä¶")
if user_input:
    # 1) –ø–æ–∫–∞–∑–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2) –¥–æ—Å—Ç–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (–†–µ—Ç—Ä–∏–≤–µ—Ä)
    ctx_docs = retrieve(user_input, k=5, chroma_path="data/chroma", collection_name="kb_docs")
    context = "\n\n".join([f"[{i+1}] {d['text']}" for i, d in enumerate(ctx_docs)])

    # 3) —Å–æ–±—Ä–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
    messages = [{"role": "system", "content": system_prompt}]
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–≥—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    messages.append({
        "role": "user",
        "content": f"QUESTION:\n{user_input}\n\nCONTEXT:\n{context}\n\n"
                   f"–ü—Ä–∞–≤–∏–ª–∞: –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–æ CONTEXT. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏."
    })

    # 4) –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    with st.chat_message("assistant"):
        placeholder = st.empty()
        stream_text = ""

        stream = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            stream=True,
        )

        for chunk in stream:
            delta = chunk.choices[0].delta.content or ""
            stream_text += delta
            placeholder.markdown(stream_text)

    # 5) —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
    st.session_state.messages.append({"role": "assistant", "content": stream_text})

    # 6) –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    if ctx_docs:
        with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
            for i, d in enumerate(ctx_docs, 1):
                st.write(f"[{i}] {d['source']} ‚Äî {d['path']}  (score={d['score']:.4f})")
