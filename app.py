# app.py
# –ë–õ–û–ö: –∏–º–ø–æ—Ä—Ç–æ–≤ –∏ –±–∞–∑–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞
import os
import sys
import re
import subprocess
import streamlit as st
from openai import OpenAI
from retriever import retrieve

st.set_page_config(page_title="Streamline Chat + RAG", page_icon="üí¨", layout="centered")

# ----- –ï–î–ò–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Chroma -----
# –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–∞ –ø—Ä–æ–¥–µ
CHROMA_PATH = os.getenv("KB_CHROMA_PATH", "data/chroma")
COLLECTION_NAME = os.getenv("KB_COLLECTION_NAME", "kb_docs")

def _validate_collection_name(name: str) -> str:
    n = (name or "").strip().lower()
    # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è Chroma (–∏–∑–±–µ–≥–∞–µ–º –¥–µ—Ñ–∏—Å–∞ –Ω–∞ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö)
    if not re.fullmatch(r"[a-z0-9_]{3,63}", n):
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {name!r}. –†–∞–∑—Ä–µ—à–µ–Ω—ã 3‚Äì63 —Å–∏–º–≤–æ–ª–∞: [a-z0-9_].")
    return n

COLLECTION_NAME = _validate_collection_name(COLLECTION_NAME)
os.makedirs(CHROMA_PATH, exist_ok=True)
os.makedirs("docs", exist_ok=True)

# ----- OpenAI –∫–ª—é—á -----
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞.")
    st.stop()
client = OpenAI(api_key=api_key)

# –ë–õ–û–ö: —Å–∞–π–¥–±–∞—Ä ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ + –∫–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    model = st.selectbox(
        "–ú–æ–¥–µ–ª—å",
        options=[
            "gpt-4o-mini",
            "gpt-4o",
            "gpt-4.1-mini",
        ],
        index=0,
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05)
    system_prompt = st.text_area(
        "System prompt",
        value="–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        height=120,
    )

    st.caption("–ò—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –º–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –∫–Ω–æ–ø–∫–æ–π –Ω–∏–∂–µ.")
    if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
        st.session_state.messages = []

    st.divider()
    st.subheader("–ò–Ω–≥–µ—Å—Ç –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    st.caption(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è: {COLLECTION_NAME!r} ¬∑ –ü—É—Ç—å –∫ –∏–Ω–¥–µ–∫—Å—É: {CHROMA_PATH!r}")
    if st.button("–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å docs/"):
        with st.status("–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã‚Ä¶", expanded=True) as status:
            # –ü–µ—Ä–µ–¥–∞—ë–º –∏–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏ –ø—É—Ç—å –≤ ingest.py
            env = os.environ.copy()
            env["KB_COLLECTION_NAME"] = COLLECTION_NAME
            env["KB_CHROMA_PATH"] = CHROMA_PATH
            proc = subprocess.run(
                [sys.executable, "ingest.py"],
                capture_output=True,
                text=True,
                env=env,
            )
            st.code(proc.stdout or "(–Ω–µ—Ç stdout)")
            if proc.returncode == 0:
                status.update(label="–ì–æ—Ç–æ–≤–æ", state="complete")
            else:
                st.error(proc.stderr)

# –ë–õ–û–ö: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
if "messages" not in st.session_state:
    st.session_state.messages = []

# –ë–õ–û–ö: –∑–∞–≥–æ–ª–æ–≤–∫–∏
st.title("Chat ‚Üí ChatGPT —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π (RAG)")
st.caption("–°–ª–µ–≤–∞ –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é. –í–æ–ø—Ä–æ—Å—ã –≤–Ω–∏–∑—É ‚Äî –æ—Ç–≤–µ—Ç—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ docs/.")

# –ë–õ–û–ö: —Ä–µ–Ω–¥–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# –ë–õ–û–ö: –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_input = st.chat_input("–í–æ–ø—Ä–æ—Å –ø–æ –≤–∞—à–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π‚Ä¶")
if user_input:
    # 1) –ø–æ–∫–∞–∑–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2) –¥–æ—Å—Ç–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (–†–µ—Ç—Ä–∏–≤–µ—Ä)
    try:
        ctx_docs = retrieve(
            user_input,
            k=5,
            chroma_path=CHROMA_PATH,
            collection_name=COLLECTION_NAME
        )
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Ä–µ—Ç—Ä–∏–≤–∞: {e}")
        st.stop()

    context = "\n\n".join([f"[{i+1}] {d['text']}" for i, d in enumerate(ctx_docs)]) or "‚Äî"

    # 3) —Å–æ–±—Ä–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
    messages = [{"role": "system", "content": system_prompt}]
    messages.append({
        "role": "user",
        "content": (
            f"QUESTION:\n{user_input}\n\n"
            f"CONTEXT:\n{context}\n\n"
            f"–ü—Ä–∞–≤–∏–ª–∞: –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–æ CONTEXT. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏."
        )
    })

    # 4) –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    with st.chat_message("assistant"):
        placeholder = st.empty()
        stream_text = ""
        stream = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            stream=True,
        )
        for chunk in stream:
            delta = chunk.choices[0].delta.content or ""
            stream_text += delta
            placeholder.markdown(stream_text)

    # 5) —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
    st.session_state.messages.append({"role": "assistant", "content": stream_text})

    # 6) –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    if ctx_docs:
        with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
            for i, d in enumerate(ctx_docs, 1):
                st.write(f"[{i}] {d['source']} ‚Äî {d['path']}  (score={d['score']:.4f})")
